Using TensorFlow backend.
Number of samples: 10000
Number of unique input tokens: 82
Number of unique output tokens: 100
Max sequence length for inputs: 286
Max sequence length for outputs: 334
Train on 8000 samples, validate on 2000 samples
Epoch 1/10
8000/8000 [==============================] - 526s 66ms/step - loss: 0.5149 - val_loss: 0.7045
Epoch 2/10
8000/8000 [==============================] - 531s 66ms/step - loss: 0.4328 - val_loss: 0.6039
Epoch 3/10
8000/8000 [==============================] - 530s 66ms/step - loss: 0.3864 - val_loss: 0.5603
Epoch 4/10
8000/8000 [==============================] - 527s 66ms/step - loss: 0.3639 - val_loss: 0.5385
Epoch 5/10
8000/8000 [==============================] - 532s 67ms/step - loss: 0.3474 - val_loss: 0.5104
Epoch 6/10
8000/8000 [==============================] - 539s 67ms/step - loss: 0.3337 - val_loss: 0.4942
Epoch 7/10
8000/8000 [==============================] - 539s 67ms/step - loss: 0.3223 - val_loss: 0.4789
Epoch 8/10
8000/8000 [==============================] - 543s 68ms/step - loss: 0.3122 - val_loss: 0.4651
Epoch 9/10
8000/8000 [==============================] - 539s 67ms/step - loss: 0.3030 - val_loss: 0.4545
Epoch 10/10
8000/8000 [==============================] - 539s 67ms/step - loss: 0.2947 - val_loss: 0.4429
